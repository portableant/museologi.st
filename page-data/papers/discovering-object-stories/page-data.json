{"componentChunkName":"component---src-templates-papers-page-js","path":"/papers/discovering-object-stories/","result":{"data":{"markdownRemark":{"html":"<h2>Abstract</h2>\n<p>This  paper  explores  the  application  of  Recogito  Studio  for  annotating  unstructured museum data to create semantic links and visualisations. The study focuses on a sample dataset from National Museums Scotland, which includes metadata about navigational instruments from the 19th and early 20th centuries.</p>\n<p>The authors aimed to develop methods for converting unstructured data into structured formats  using  Recogito  Studio.  Recogito  Studio  facilitates  semantic  annotation  by allowing users to highlight and tag entities and relationships in texts and images, and link places to online gazetteers.</p>\n<p>The data model was developed using Linked Art and CIDOC CRM standards, with some bespoke terminology. Annotations focused on unstructured text fields, using Recogito Studio’s Geo-Tagger plugin to identify and tag geographical locations.</p>\n<p>The  geo-tagged  data  was  exported  and  visualised  using  Peripleo,  requiring  several data transformations to ensure compatibility. A user evaluation with cultural heritage professionals revealed usability challenges and areas for improvement, with Recogito Studio receiving a UMUX score of 73.3 and recommendations include enhancing geo-tagging, incorporating Named Entity Recognition, and developing automated workflows for Linked Open Data production.</p>\n<h2>1. Context and Motivation</h2>\n<p>Alongside the structured collections metadata found in databases and collections management systems,  museums  hold  vast  quantities  of  unstructured  data,  in  the  form  of  descriptions, research  notes,  and  exhibition  labels.  Contained  within  this  text  is  a  wealth  of  information with exciting potential for data storytelling, revealing and visualising these objects’ itineraries, i.e.  their  journeys  through  space  and  time  (Dunn  et  al.,  2019).  Examples  from  our  dataset include a replica of an astrolabe that accompanied the Spanish Armada before being recovered on an Irish island over 250 years later, as well as a sextant used by a named crew member in the navigation of the 1902–1904 Scottish National Antarctic Expedition. However, converting these data to a more structured format using existing freely available tools for working with tabular datasets requires substantial data manipulation, complexity and, of course, time. Our study sought to develop methods and approaches to achieve these goals, via the potential for applying semantic annotation using the newly developed Recogito Studio platform.</p>\n<p>Recogito  was  originally  an  online  platform  developed  through  the  Pelagios  Network  (Simon et al., 2015, 2017, 2019). It facilitates semantic annotation by providing an interface where researchers  without  substantial  technical  experience  can  highlight  and  tag  entities  and relationships in texts and images. In addition to performing this task manually, users have the option to apply Named Entity Recognition (NER) from external services, which automatically detects  places,  people  and  events.  For  places,  Recogito  provides  the  additional  functionality of  linking  to  their  equivalents  in  online  gazetteers.  These  data  can  be  exported  in  multiple\nformats, including Linked Open Data.</p>\n<p>The Pelagios Network itself started life as the Pelagios Project, with its initial remit to facilitate the  connection  of  ancient  texts  to  the  places  mentioned  within  them  (Vitale  et  al.,  2021). Alongside  Recogito,  the  Pelagios  team  developed  Peripleo,  a  web-based  spatial  visualisation that  facilitates  the  discovery  of  digitised  objects  from  multiple  sources,  based  on  their annotated places (Simon et al., 2016). Through several rounds of funding from Jisc, the Arts and Humanities Research Council (AHRC) and the Mellon Foundation, Pelagios expanded its geographic/temporal scope, and became a community-led network, whose members contribute their expertise to several activities, including annotation (Kahn et al., 2021).</p>\n<p>As  part  of  this  shift  from  a  project  to  a  network,  development  of  both  Recogito  and  Peripleo has been continued by Pelagios partners in conjunction with other initiatives. Following the British  Library’s  ‘Locating  a  National  Collection’  project  (Rees  et  al.,  2022),  Peripleo  is  now available  as  a  GitHub  repository  that  can  be  cloned  and  customised  with  a  dataset  of  the\nuser’s choosing, then deployed on GitHub Pages (Gadd et al., 2024). Recogito was redeveloped with  funding  from  the  University  of  Bonn  (Universität  Bonn,  2024),  which  reimagined  it  as a  modular  system,  renamed  Recogito  Studio  (Performant  Software,  n.d.).  Its  core  application promotes  collaborative  manual annotation, with  the  potential  for  the  development  of  future plugins to provide additional functionality. The first of these, the Geo-Tagger plugin (Simon, 2024),  partially  replicates  one  of  the  features  of  the  original  Recogito  by  allowing  users  to associate annotated places with their equivalent entries in online gazetteers and authority files.\nLike  Peripleo,  Recogito  Studio  is  available  to  install  as  user-customised  instances  (Jameson  &#x26; Simon, 2024), rather than as a single, centralised platform.</p>\n<p>Although  Recogito  Studio  was  initially  focused  on  classroom  use,  its  predecessor  had  been successful in empowering researchers to create structured data via a usable annotation interface, and steps had already been taken by the Pelagios Network to engage with the cultural heritage sector. Following the release of the new platform, there was already interest in continuing this work,  in  order  that  cultural  heritage  practitioners  might  derive  similar  benefits  and  provide input  into  further  developments.  This  paper  discusses  our  application  of  the  Recogito  Studio platform  to  a  sample  of  collections  data  (19th  century  navigational  instruments  at  National\nMuseums Scotland), to evaluate its potential for use in a cultural heritage context. Alongside our experiences of data annotation and visualisation, we discuss the outcomes of preliminary user evaluation and provide our reflections on findings so far, as well as their implications for future work.</p>\n<h2>2. Dataset Description</h2>\n<ul>\n<li>Repository Location: <a href=\"https://doi.org/10.21954/ou.rd.27323799.v1\">https://doi.org/10.21954/ou.rd.27323799.v1</a></li>\n<li>Repository Name: The Open University Research Repository (Figshare)</li>\n<li>Object Name: Annotated Object Itineraries for Museum Collections Data</li>\n<li>Format Names and Versions: PDF, OWL/XML, CSV, GeoJSON, JSON-LD</li>\n<li>Creation Dates: 2024-05-01 - 2024-10-29</li>\n<li>Dataset Creators: Sarah Middle, Elton Barker, Maria Aristeidou (Open University)</li>\n<li>Language: English</li>\n<li>License: CC BY 4.0</li>\n<li>Publication Date: 2024-10-29</li>\n</ul>\n<h2>3. Method</h2>\n<p>The  dataset  used  for  the  work  discussed  in  the  paper  is  a  sample  of  collections  data  from National Museums Scotland (NMS), comprising metadata about 385 navigational instruments of  several  types,  from  the  19th  and  early  20th  centuries.  These  include  sextants,  quadrants, compasses,  and  astrolabes,  many  of  which  played  a  crucial  role  in  exploration  and  survey expeditions,  with  links  to  imperial  expansion  and  colonialism.  Collections  metadata  at  NMS is managed using the Axiell collections management system (Axiell, 2024); the system is fully compliant with version 4.0 of the Spectrum standard (Collections Trust, 2016) and partially\ncompliant with version 5.1 (Collections Trust, n.d.). While NMS’ approach to collections data management  facilitates  the  representation  of  much  of  the  fundamental  information  about these objects as structured data, there are rich details contained in unstructured fields, such as research notes, descriptions, and previous exhibition labels.</p>\n<h3>3.1 Data Model Development</h3>\n<p>We  started  work  on  the  data  model  through  analysing  the  NMS  dataset  and  extracting  the\nentities and relationships mentioned in column headings, to produce a draft sketch of the key\nelements for expressing object itineraries. This was visualised as a network with the object at the\ncentre, linked both to related entities and events in its itinerary. In doing so, we quickly realised\nthat the type of information included here is largely covered by CIDOC CRM. As the intention\nwas  always  to  produce  a  lightweight  data  model,  our  thoughts  turned  immediately  to  using\nLinked Art (Linked Art Editorial Board, n.d.-a), which was developed as an extensible, usable,\nlightweight subset of CIDOC CRM, with additional terms as required. Using the documentation\nof both CIDOC CRM and Linked Art, we mapped the entities and relationships from our diagram including references to\nequivalent terms in Linked Art/CIDOC CRM is shown in Figure 1). Notably, Linked Art/CIDOC\nCRM entities are often defined using types (e.g. rather than creating additional subclasses to the\nEvent class, a particular type of Event can be classified using a term from a relevant external\nvocabulary);  the  Linked  Art  documentation  advises  that  types  should  be  provided  from  the\nGetty’s Art and Architecture Thesaurus (AAT) (Getty Research Institute, 2023), where available\n(Linked  Art  Editorial  Board,  n.d.-b).  For  those  types  not  available  in  AAT,  we  suggest  using\nterms  from  Wikidata  (Wikimedia,  2023),  increasingly  used  by  the  cultural  heritage  sector\n(Zhao, 2023).</p>\n<p>Using our template diagram (Figure 1), a formal specification for our data model was generated\nin the OWL 2 Web Ontology Language (W3C OWL Working Group, 2012) using Protégé (Musen,\n2015), which also incorporated the Linked Art/CIDOC CRM superclasses and superproperties\nand  the  relationships  between  them.  We  used  this  exercise  as  an  opportunity  to  define  the\nboundaries of our scope. CIDOC CRM allows further modelling of data about people, e.g. birth,\ndeath, and occupation, but we decided not to include these aspects to maintain our focus on the\nobjects. This information can also be gleaned through linking person entities to authority file\nentries, rather than stating it explicitly as part of an object itinerary.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1314px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAABYlAAAWJQFJUiTwAAACSUlEQVR42i2SSW/TUBRG8wvZ0RYkFvALkFgwdNU9a/4ACAS0UFSQKkGrQNt0pE2aOHHSJB4ST4kdO3PaDIdrB1tHz8N7x9+9z6lnr7/xeGObJxtbPFp/z+rzj6y+/Cxssibjw/Ut4UvCygt5Lqw8/8R9mbf2ajPhgcy59/Qtbz7skTq4rFEzPRpugN3qYDoBarVBpaZTvGlSrrvcGDZV3UYzHXnvU7fauH4Py+vSFFy/T63hc1kySYWdkCAI6feHzOcLvG7IiZonW8lxki1wplTI5BUOr7LkqwrZWpma57IAup2AKAwZDIYMhdFoREozHAz5chj1E6Hl+6QL1xyIdL94xV7+nD9yf1hSOVJVGYs0/Dbx4dpN2l6L6XQma+cMhyL0OxFN26VpeYnQDTscKQWOS4KqSNoCF5WSUOairHKqltAlYXwEtoHf9kU4ZbFYSMIxKcv2cDyf3mDMbDYn6HXJ1WsUNA3FMASdvK5R0HVBI1er4vd6idC3TNqtNr3egPH4dlmyLUJPNqMfC6dzmRwL6yimwfX/sWAsZYlcqxMN+onQsRxJ2F4mlHMk0lSjGffQFmkgscGTRmeKeU7LZU6kzEMpMSZdVEgr1+xLO+xulAg9WdcW4Z0Emc8mhF6W1I38HjmlLH30WMxBb9lsn2fY/XvKr8tjds7SfBd2zn/z4+wnXzO7HFfyS2FDgkg/43ZFoYulviNlNCxiqeW0mExu8aMo6V1JylMNjUrDoGzqCfG1atZxA5+Z7KrnNAkkYbzu7m5CP7L5B/C+xnlWRCTXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/73f76cee0d271bb90d893edb7e13aada/4be29/figure-1-oi.webp 500w,\n/static/73f76cee0d271bb90d893edb7e13aada/03f31/figure-1-oi.webp 1000w,\n/static/73f76cee0d271bb90d893edb7e13aada/d0c29/figure-1-oi.webp 1314w\"\n              sizes=\"(max-width: 1314px) 100vw, 1314px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/73f76cee0d271bb90d893edb7e13aada/c6e3d/figure-1-oi.png 500w,\n/static/73f76cee0d271bb90d893edb7e13aada/da8b6/figure-1-oi.png 1000w,\n/static/73f76cee0d271bb90d893edb7e13aada/2f41e/figure-1-oi.png 1314w\"\n            sizes=\"(max-width: 1314px) 100vw, 1314px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/73f76cee0d271bb90d893edb7e13aada/2f41e/figure-1-oi.png\"\n            alt=\"Figure 1 Diagram showing the data model used as the basis for annotation, referencing equivalent CIDOC CRM and Linked Art terms (green coloured nodes signify references to external vocabulary terms).\"\n            title=\"\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Figure 1 Diagram showing the data model used as the basis for annotation, referencing equivalent CIDOC CRM and Linked Art terms (green coloured nodes signify references to external vocabulary terms).</figcaption>\n  </figure></p>\n<p>Data model development continued via a process of refinement and extension in parallel with\nthe  annotation  phase  of  the  project.  Annotating  the  unstructured  text  revealed  additional\ninformation,  such  as  entities  that  require  more  specific  properties  than  those  currently\nincluded  in  Linked  Art/CIDOC  CRM  (usage,  expedition  and  voyage).  While  the  data  model\nthat  accompanies  this  article  includes  these  additional  classes  and  properties,  we  recognise\nthe potential for its further extension, particularly through the annotation of data about multi-\ncultural/temporal heritage objects created for different purposes. Examples of such extensions\nmight include a more granular definition of historical event types, or human-object interactions\nthat go beyond the museum context (e.g. use or maintenance).</p>\n<h3>3.2 Annotation</h3>\n<p>Our intention from the start was to ensure that we were using annotation as a method where it\nwould provide the greatest benefit (enabling machines to understand and process information\nin a way that is similar to how humans do). Rather than annotating data in columns that were\nalready  well-structured  and  populated  by  values  from  controlled  vocabularies,  we  wanted\nto  surface  entities  that  are  currently  described  in  unstructured  long  text  fields,  and  which\ncannot easily be converted to structured data by other (readily available) means. Therefore,\nwe selected only fields that are more descriptive in nature for our annotated sample of the\nNMS data.</p>\n<p>We hoped to annotate records that reflected geographically diverse object itineraries, evaluating\nthe Geo-Tagger plugin to its full potential. To facilitate sampling of object records, we uploaded\nthe dataset to the previous version of Recogito and applied the NER functionality. This allowed\nus to view the places mentioned in these records ‘at a glance’, enabling us to identify a sample\nof nine objects whose unstructured text fields indicated geographical movement.</p>\n<p>Annotating  in  Recogito  Studio  requires  the  user  to  upload  text  (TXT)  formatted  data.\nHighlighting  text  in  the  resulting  document  prompts  the  annotation  popup  to  appear\n(Figure 2), which accepts annotations as a comment, a tag, or (if the Geo-Tagger plugin is\nenabled)  a  geo-tag.  Comments  can  include  hyperlinks,  images,  and  videos  alongside  plain\ntext. Tags are user-generated and can either be added during the annotation process or in\nthe  configuration  settings  as  a  predefined  tag  set.  On  input,  relevant  tags  that  have  either\nbeen predefined or already added to annotations on a document are displayed to the user via\nautocomplete. Finally, the Geo-Tagger plugin uses the highlighted text as a query string to\nidentify the place in the user’s selected gazetteer; the user can then select the correct place or\nmodify the query as needed. All annotations on a document can be viewed in the right-hand\npane,  which  can  be  filtered  and  colour  coded  based  on  their  visibility  (public  or  private),\ntheir creator, or their first tag (Figure 3). Geo-tags can additionally be viewed as a simple\nmap visualisation (Figure 4) and exported as GeoJSON data or a PNG image.1</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1312px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40.8%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABzUlEQVR42n2RzWsTURTF519zZXUp+DcoaMVKQFyLGxERVy79qAT8wK8ktUJbpYld1FQQNYlpkplJZibWZr6SyUxmkvy8eaQLNz44HN6755177nva9fubnMvlOZ97yMqVp//gzBIrq+uyX+f06hKXnyhWtat5zq7lOXXxEdfubqB9qrZ5tf2dzUqN4m6dYrnORqVBSfgE7z83KcnZ1n6H7S86O1WDD3tNCnuHvH1c5N2LjxREUz5ooU0mCTBnPpsJLSFrOs1wejpWV8c1G2SRr86ZL7QZWZoQBi7hkU0yWtRmLLw01wsJhzFBOCYYjvHDiEmaSTGl1WpTqzewej08N1D1YZQoHo0TDMPE7FpYTp/BwCVJJmi+P2Q4SgSxQijiNJuSZRm2baPrBn4QqAYTuZAKT6VhJIa/moeqabvdwen3xTD5v6Fhmhi6zrd6l/0fFj87x9T0Ac2uR6HSYqv8VdKbdDo6vu9LU5VwJEaTpWmixk/TKTN5U8t2cI+PePBslws3n5O784Yb9wqs3X7NpVsvKe1U8b0Btozseb4KoQ1cH09SnmDxpuNxrOI7jiNjO/z57cgHGdhdg57RoWfKiJbsrZ5o+koXRRFxHPMXoRgykFooXKcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/4be29/figure-2-oi.webp 500w,\n/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/03f31/figure-2-oi.webp 1000w,\n/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/4d52f/figure-2-oi.webp 1312w\"\n              sizes=\"(max-width: 1312px) 100vw, 1312px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/c6e3d/figure-2-oi.png 500w,\n/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/da8b6/figure-2-oi.png 1000w,\n/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/a2880/figure-2-oi.png 1312w\"\n            sizes=\"(max-width: 1312px) 100vw, 1312px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/8d8a9e395b1fc9e8491ab5748ad0d9a4/a2880/figure-2-oi.png\"\n            alt=\"Figure 2 Screenshot showing the annotation popup in Recogito Studio.\"\n            title=\"\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Figure 2 Screenshot showing the annotation popup in Recogito Studio.</figcaption>\n  </figure></p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1312px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 96.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAACuUlEQVR42nVUiXabQAzM//9aX9u8vrqNG8cX2BhwWG5YrulIix07B++Ja1ejkUbah6ZpMAwD+r6/s67v8HfziNOrh2ma0HWW/7vZ+g8mGIL1YK3FV9fa2yLJEn0XUH1i0vtnl2ARsJ0/ZdM4P50tdwHCJNX3uq7IoL4BmyQKxnHkw/kJ1hVQfvakPeoiNDUBcWuDrovz09ZHkhd3rB2Y1YBXwIGbfzytYYpSN/RDj6LIWZvepdM2MKlhTQ2q1vkUdYsFA+RlgYxrTdvcp9yQUd9bZeOMhWbkx+ctFhsPLfde9lsKkWQZ9sdgDp7dM5RL2P3zAgVSNblRgF9Nioxpyt6WLCT4JoiwPgSoyO41L9kF3XvASdkkWa6OwrblBgGsqgJ1VRKsxsg6V1WlAcWnqBqs/FCl6m5FGTVF129NXSKMY5cmI0sdx3Hgew//bMg2VzbC9rbt7lQWp2ZWNWPq/imCH51Rko2AjVzP+S4laRVk0mYebjpjBnQR/CjBcs+atJa1ObEHD/pfUpX0JH1RehvE+EmRyrrB2Zzwa/WNHdK/AeZZioKFjdIcXpyg5PiAokg6wkxGcLE94DfTL5lBxXVDgSoNZPmdI04z9ZPvh5Jg2mvXVhlVHKldnmcaNWUJTFGo6legumaAmiqXeN75nCijZdGUBcR1ekNRWrww5c0xdJPLNVFvGod5empNb3eK1eT6vlhitT+QWPd+lt9GaZwBZP3yFJMu8MIXClNf1c3KCpYdIGufALqhb8hEmFnpPQHnZnEQVcPkAC+KsAsT1rDVEmwOSwRn/x5wgpM/TgO1IMkRmhyRyQiQEHjCOT0hSo44Z6WmLHWUht+TdZQEnwNG5kjAE1bsuR1HbM+e/LPe0dEiNnKk+V+fhyKEHEuXJhW7HEvW8jTv3aR0tplFcib/nM1+46Cz/B8ircTMRiIragAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/10781f5f8b9e8e4f1788077d4fa21a6d/4be29/figure-3-oi.webp 500w,\n/static/10781f5f8b9e8e4f1788077d4fa21a6d/03f31/figure-3-oi.webp 1000w,\n/static/10781f5f8b9e8e4f1788077d4fa21a6d/4d52f/figure-3-oi.webp 1312w\"\n              sizes=\"(max-width: 1312px) 100vw, 1312px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/10781f5f8b9e8e4f1788077d4fa21a6d/c6e3d/figure-3-oi.png 500w,\n/static/10781f5f8b9e8e4f1788077d4fa21a6d/da8b6/figure-3-oi.png 1000w,\n/static/10781f5f8b9e8e4f1788077d4fa21a6d/a2880/figure-3-oi.png 1312w\"\n            sizes=\"(max-width: 1312px) 100vw, 1312px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/10781f5f8b9e8e4f1788077d4fa21a6d/a2880/figure-3-oi.png\"\n            alt=\"Figure 3 Screenshot showing viewing, filtering and colour coding options in Recogito Studio.\"\n            title=\"\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Figure 3 Screenshot showing viewing, filtering and colour coding options in Recogito Studio.</figcaption>\n  </figure></p>\n<p>\n        <div class=\"ratio ratio-16x9\">\n            <iframe\n              title=\"\"\n              width=\"800\"\n              height=\"400\"\n              src=\"https://www.youtube-nocookie.com/embed/LQnPs1Lhc1Q?rel=0\"\n              class=\"embedVideo-iframe\"\n              style=\"border:0\"\n              \n              \n              loading=\"lazy\"\n              allowfullscreen\n\t      sandbox=\"allow-same-origin allow-scripts allow-popups\"\n            ></iframe>\n        </div></p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1312px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABrElEQVR42kWSW1PiQBCF8/9/yPrgamlxqVJBZV11ES3BAELIZXKZGQIhgYDWvp09k2jtw6mazNfTfbo71iJJ0JkEuHmvdTXxK93NBHSq4ZBf877StOaXYx+PToh0pTEK4uquNwsQpWtYz36EDgPHUQyhFQb8/u0I2GEMR0o0Xxz8fJphrhTCpcIfN8QjNYkSLBKJO8bezkVVOM8zWG1WEzLBR7FEsVlWATd0J/m4NVzgx/0U3b6Nv9sUMz/E1dRnwRDrta5cm67SVOFQaOSbFazenFZljGcvRJ+VG7aP06GHLgMfmLzP+4gFn8h67z7ORh5OKdOi6WTgCogkZmzAjnTtsMOqJ68uLsws6e6cD4xMkrbN5OTH5F0yM56zkYumXfNWxQMccTSvQsIy0CT6xTk8LEKe6+QtOm2+eWhQl0xo+D0dtcceToYujJHGFzdFbul4GitYQpn+U+w5o89dCsl5vIkYesUlaImAiynz/1woiTEXtuSGfZ4V/4QPsj13UBbc8mGbYcfDt8oiY0DGBBk+yw0SpaG4ffO9Jd9/cfPusKvjzLttvkK5K/AP2b46BLjZR6oAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/f2ebff9bee1b9674e404acabe2c85a42/4be29/figure-4-oi.webp 500w,\n/static/f2ebff9bee1b9674e404acabe2c85a42/03f31/figure-4-oi.webp 1000w,\n/static/f2ebff9bee1b9674e404acabe2c85a42/4d52f/figure-4-oi.webp 1312w\"\n              sizes=\"(max-width: 1312px) 100vw, 1312px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/f2ebff9bee1b9674e404acabe2c85a42/c6e3d/figure-4-oi.png 500w,\n/static/f2ebff9bee1b9674e404acabe2c85a42/da8b6/figure-4-oi.png 1000w,\n/static/f2ebff9bee1b9674e404acabe2c85a42/a2880/figure-4-oi.png 1312w\"\n            sizes=\"(max-width: 1312px) 100vw, 1312px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/f2ebff9bee1b9674e404acabe2c85a42/a2880/figure-4-oi.png\"\n            alt=\"Figure 4 Map visualisation of geo-tagged places generated by Recogito Studio.\"\n            title=\"\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Figure 4 Map visualisation of geo-tagged places generated by Recogito Studio.</figcaption>\n  </figure></p>\n<p>It  became  clear  that  translating  the  object  itineraries  data  model  into  a  tagging  system  that\ncould  be  used  consistently  by  different  users  (or,  indeed,  by  the  same  user  during  different\nannotation sessions) required a set of guidelines to standardise the process. We developed an\n‘annotation  protocol’  (deposited  alongside  the  annotation  data),  stating  which  combination\nof tags to use on particular entities. This improved our workflows, and was a useful exercise\nthat highlighted inconsistencies in the annotation, as well as identifying gaps within the data\nmodel. Emphasis should be placed on how annotation within Recogito Studio is highly flexible,\nallowing users to create their own set of tags, and we would not want to inhibit this process\nby implying that our approach is ‘correct’. However, the annotation protocol and data model\nmight provide a useful starting point for those interested in using Recogito Studio for a similar\npurpose.</p>\n<p>We  found  that  the  object  records  often  contained  repetition,  with  the  same  piece  of\ninformation about a particular entity included multiple times (e.g. descriptions and label fields\ncan be similar in content). As this information is only useful to capture once for the purpose of\nproducing object itineraries, entities were usually only annotated the first time they appear in\nan object record, unless augmented information is included alongside later mentions. Entities\nincluding  object  types,  materials  and  techniques,  which  would  benefit  from  alignment  with\nterms from sources such as AAT and Wikidata, were tagged with a normalised version of the\ntype, which might then be mapped to their equivalent URIs to facilitate their conversion to\nLinked Data later.</p>\n<p>Once  we  had  annotated  all  the  object  records  in  our  sample  dataset,  we  exported  the\nannotations as a CSV file, with their geo-tags additionally exported in GeoJSON format.</p>\n<h3>3.3 Visualisation</h3>\n<p>After exporting the geo-tags as GeoJSON, we investigated how this data might be visualised\nusing Peripleo (introduced in section 1). A Peripleo site can be set up in GitHub Pages using\nits code repository and accompanying tutorial (Gadd et al., 2024), with JSON-LD data that\nis compliant with the Linked Places format  (Grossner  et al.,  2024).  For our exported Geo-\nTagger data from Recogito Studio, we found that several transformations needed to be made\nto the GeoJSON export to ensure compatibility with Peripleo, thereby enabling visualisation\nof the data:</p>\n<ol>\n<li>Replace “\"type\":\"FeatureCollection\",” with “\"@id\":\"DATASET URL\",\"type\":\"FeatureCollection\", \"@context\":\"<a href=\"https://w3id.org/locolligo/contexts/linkedplaces.jsonld%22,%E2%80%9D\">https://w3id.org/locolligo/contexts/linkedplaces.jsonld\",”</a></li>\n<li>Replace “\"id\"” with “\"@id\"” throughout</li>\n<li>Save as .json</li>\n</ol>\n<p>Whilst the tutorial documentation advises that, for data exported from Recogito, the data file\nformat should be described as “RECOGITO_IMAGE” in the config file, this refers to the previous\nversion of the Recogito platform. Instead, the file format for data exported from Recogito Studio\n(and  transformed  using  the  above  process)  should  be  described  using  the  default  data  file\nformat “LINKED_PLACES”.</p>\n<p>While  the  steps  above  create  an  interactive  map  visualisation  in  Peripleo,  the  exported  data\nfrom  Recogito  Studio  lacks  contextual  information  about  the  annotations  and  objects.  The\nvisualisation is thus just a collection of points on a map. Since Recogito Studio annotations cannot\nbe  identified  using  URIs,  we  manually  updated  the  data  export  to  include  links  to  relevant\nobjects  in  the  NMS  online  catalogue  and  the  context  of  the  geo-tagged  text.  To  emphasise\nthe connection between map locations  and museum objects, we  added an 'Object Identifier'\nproperty to the dataset and configured the visualisation to display these identifiers as a facet\nwhen the filter icon is clicked (Figure 5).2 Using Recogito Studio for data annotation, despite\nthe extra manual processing, is a crucial first step in preparing data for visualisation in Peripleo\nwithout needing substantial technical expertise.</p>\n<p><figure class=\"gatsby-resp-image-figure\" style=\"\">\n    <span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1308px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.6%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB1ElEQVR42iWS227TQBRF8+tIfEYANYVKSEhpK6oi2hRaUfHQpOktNI4d22OPZzy+5kIpPC1O0oclW7K8z15Hp2MKh3aOqq6JihpbN7RlzqLK+RmmnHiK05niTPgmnHgx3/2EcazJXE5bOxaNo3AGU1Z0ynLBevlMWpS4psUK69pypxI+3vq8G83oDj3uY4WXJHx5DLmJEyKjKUsjgy2rxlK5jKoq6WTqE4U94DYuGUYJF2Em0xN2rn0OH+bsjAMG05BQwiKdspBhz22+DVnKeyuhqybHGUUptp3X/T6v9g8x9YJ5lnAgIZtW78c+PaE/+sVg4nMnQwqnWUtQK602zbaBlRFtS1Nkoi4Nj/ZW9Ht/WD8ZMpMx8KJtu93xC8e3E4JgRmNSsjTB5KIqepuAunh5FvJtUWpWrezw384Bf7v7uOcVxw/BNmTvJuCD0LsOuPQVV6HiQrSHQYSfKCKhsanobpoalqKtZKdhLsrp6Ih4+JnTeU736pG3I2/LG2F37DGLIpys4l4pJnEs+06JtTTVElpoqjzld224nPr8mGd0RmnJNK/lJGLO5RwGXsKZ8HWaMAy1qFhqZ3mS06jllGxumSSaG6Wxcjax1ujccC7/T23Jfw78PH/q9GVUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/static/b1985e2e5246bc4938f28085c35729da/4be29/figure-5-oi.webp 500w,\n/static/b1985e2e5246bc4938f28085c35729da/03f31/figure-5-oi.webp 1000w,\n/static/b1985e2e5246bc4938f28085c35729da/ed702/figure-5-oi.webp 1308w\"\n              sizes=\"(max-width: 1308px) 100vw, 1308px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/static/b1985e2e5246bc4938f28085c35729da/c6e3d/figure-5-oi.png 500w,\n/static/b1985e2e5246bc4938f28085c35729da/da8b6/figure-5-oi.png 1000w,\n/static/b1985e2e5246bc4938f28085c35729da/da1d8/figure-5-oi.png 1308w\"\n            sizes=\"(max-width: 1308px) 100vw, 1308px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/static/b1985e2e5246bc4938f28085c35729da/da1d8/figure-5-oi.png\"\n            alt=\"Figure 5 Screenshot showing Peripleo visualisation of enhanced geo-tagged data.\"\n            title=\"\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span>\n    <figcaption class=\"gatsby-resp-image-figcaption\">Figure 5 Screenshot showing Peripleo visualisation of enhanced geo-tagged data.</figcaption>\n  </figure></p>\n<h3>3.4 User Evaluation</h3>\n<p>Another  key  component  of  our  study  was  its  evaluation  by  our  target  audience  of  cultural\nheritage  professionals.  While  our  experiences  had  been  largely  favourable,  we  aimed  to  test\nhow usable and useful the platform would be to those less familiar with its predecessor, and\nwith semantic annotation more generally.</p>\n<p>Recogito Studio was assessed using an iterative, mixed-method design with user testing. This\napproach,  based  on  Nielsen  and  Landauer’s  (1993)  methodology,  involves  multiple  small-\nscale  tests  with  up  to  five  users  for  high-quality  evaluation.  Participants  were  briefed  and\ngave informed consent before the in-person testing on 11 June 2024 at a workshop in Historic\nEngland’s  head  office  in  London.  The  usability  assessment  had  two  stages:  a  think-aloud\nprotocol for seven tasks and a brief user experience survey. In the first stage, two facilitators\nguided  five  participants  (n  =  5)  through  task  scenarios  that  mirrored  real-life  activities.\nThe  participants,  who  included  two  female  and  three  male  practitioners  from  universities,\nmuseums, and archive centres, had no prior experience with Recogito Studio, though two had\nused similar tools.</p>\n<p>The  primary  goal  was  to  identify  usability  challenges  by  having  participants  verbalise  their\nthoughts  while  completing  tasks.  The  20-minute  test  included  functions  like  locating  and\nopening documents, annotating words, creating geo-tags, adding comments or tags, accessing\nthe map view, using filters, visualising tagged words, downloading annotations, and assigning\ndocuments.  Facilitators  observed  and  scored  each  task  on  a  3-point  scale  and  noted  user\nfeedback for analysis.</p>\n<p>In  the  second  stage,  a  post-test  survey  was  conducted  where  participants  completed  the Usability  Metric  for  User  Experience  (UMUX)  (Finstad,  2010)  and  answered  additional questions about their role, likes and dislikes about the platform, and potential use cases for Recogito  Studio.  The  UMUX,  designed  to  measure  perceived  usability  with  four  items,  was slightly adapted for Recogito Studio’s specific functions. Participants rated each statement on a seven-point scale, and scores were adjusted to generate an overall usability score from 0 (poor) to 100 (excellent).</p>\n<p>The resulting GitHub Pages site can be found on <a href=\"https://sarahmiddle.github.io/Peripleo_PelagiosOSC\">Sarah Middle's profile</a>.</p>\n<h2>4. Results and Discussion</h2>\n<h3>4.1 User Evaluation Findings</h3>\n<p>During the above evaluation, most users found the task of Finding and Opening the Map View intuitive. Four out of five users easily located the map, though one participant initially clicked through other screen options before identifying the correct icon. While most users found the map without issue, some commented that the icon could be clearer, as they were unsure whether it represented a map or a language change option.</p>\n<p>Adding Comments or Tags to Annotations was straightforward for all users. However, one participant accidentally closed the window without saving their tag. They realised this mistake and reopened the window to complete the task. Similarly, Locating and Opening Files was\ngenerally easy for users, though one person initially searched for a non-existent search function,\nleading them to manually check folder labels to find the document.</p>\n<p>Some tasks presented more challenges. For example, Finding the Filtering  Button was difficult for two out of five users, as they expected filters to be located on the right side of the screen rather than the left. These users eventually found the button but suggested that the icon could be more intuitive. Similarly, Creating Geo-tags proved tricky, with two users failing to notice the geo-tagging option after annotating words. Another participant mistakenly left the default U.S. location for London without realising the error.</p>\n<p>Assigning  Documents  also  posed  difficulties.  Three  out  of  five  users  struggled  to  locate the assignment  option,  often  searching  through  menus  on  the  document  page.  Two  users  had trouble finding the 'new assignment' button because it was hidden off-screen. One participant noted  that  the  'next'  button  used  to  complete  the  form  fields  was  also  not  visible  without scrolling. Lastly, none of the participants could use the Download Annotations CSV without help. Most users initially searched through the document menus, but only three out of five eventually located the download option after being guided to the correct menu.</p>\n<p>The usability metric for user experience (UMUX) revealed mixed results. While most participants rated Recogito Studio positively, with scores ranging from 5 to 7 (out of 7) for meeting their needs,  two  users  gave  notably  lower  scores  (2–3)  for  overall  usability.  One  participant,  in particular,  found  the  process  of  editing  annotations  to  be  time-consuming  and  frustrating. Overall, Recogito Studio received a UMUX score of 73.33%, which suggests a generally positive user experience but highlights room for improvement, particularly regarding ease of use.</p>\n<p>Participants  praised  Recogito  Studio’s  automatic  location  identification  via  gazetteers  and Wikidata,  finding  it  helpful  for  enriching  information.  They  also  appreciated  the  flexibility to annotate text with comments and geo-tags, the visual map displaying all locations, and the ability to share and assign documents for collaboration. Several improvements were suggested: more consistent placement of control buttons to avoid unnecessary scrolling, a search function to locate files more efficiently, automatic object tagging, enhanced visibility of the geo-tagging feature,  and  adjustments  to  the  map  display  to  prevent  it  from  obscuring  chosen  locations.\nParticipants  also  recommended  a  more  intuitive  way  to  download  annotations  and  clearer visual cues for document assignment.</p>\n<h3>4.2 Our ‘Super User’ Experiences</h3>\n<p>We  have  evaluated  Recogito  Studio  as  'super  users'  and  reflected  on  its  use  for  annotating cultural heritage data. While we concur with user evaluations regarding usability and potential improvements, we would like to emphasise additional points.</p>\n<p>To  address  participant  concerns  about  the  Geo-Tagger  plugin,  we  propose  extending  its functionality to geolocate places to polygons and enabling simultaneous queries from multiple gazetteers, similar to the previous Recogito version.</p>\n<p>Recogito Studio’s previous iteration included Named Entity Recognition (NER) for people, events, and places, with the latter linked to gazetteer URIs. While not originally scoped for Recogito Studio,  NER  would  significantly  enhance  data  generation  efficiency,  especially  for  resource-constrained  researchers  and  professionals.  Expanding  this  functionality  to  link  other  entity\ntypes (e.g., people to VIAF, objects to Getty AAT) would further enrich cultural heritage data annotation, enabling more effective representation of object itineraries. We might also consider adopting an approach similar to that developed by Luthra et al. (2023) for automated entity recognition in Dutch East India Company probate records. Here, the authors used a bespoke taxonomy to annotate information about people who were not mentioned by name, thereby surfacing  a  greater  depth  of  narratives  involving  interactions  with  indigenous  and  enslaved people.</p>\n<p>Of  particular  interest  to  our  study  is  the  conversion  of  annotation  data  to  RDF,  a  feature available in the previous Recogito platform, to increase its discoverability and interoperability. There  exist  various  online  tools  for  converting  CSV  to  RDF,  as  well  as  frameworks  such as  Candela's  (2023)  for  converting  more  structured  metadata.  However,  Recogito  Studio complicates this process due to the inability to annotate relations between entities. We partially mitigated this by annotating entities with their properties, but additional processing of the CSV export is still required to ensure accurate RDF representation.</p>\n<p>Although Recogito Studio generates a unique identifier for each annotation, these identifiers do not act as resolvable URIs. Therefore, even if a user were to convert their annotations to RDF, it is not currently possible for them to link back to them, thereby pointing to the source(s) used for their work. For example, it was initially anticipated that the locations pinpointed on the Peripleo visualisation might link to the annotations in which they were identified; however, as this was not possible, they currently only include links to the online catalogue records for the relevant objects. Again, this would be another useful feature to include as part of any future development of Recogito Studio.</p>\n<p>Although  the  GeoJSON  export  from  Recogito  Studio  provided  a  good  starting  point  for visualisation using Peripleo, further processing is required before the resulting file is compatible with Peripleo, and with the Linked Places format more generally. Additionally, our particular visualisation incorporates data enhancements, to increase its usefulness within the context of representing  object  itineraries  for  a  small  sample  of  museum  objects.  However,  it  would  be difficult  to  reproduce  a  similar  result  on  a  larger  scale  as  these  enhancements  necessitated manual editing, rather than being produced automatically as part of the Recogito Studio export.\nThe result is therefore likely to conceal, rather than highlight, information about the object’s itinerary, historical context, and (in many cases) its colonial past. As this is a limitation of the Recogito  Studio  software,  rather  than  the  data  structure,  this  process  might  be  improved  by developing an automated, customisable workflow to allow the conversion of a Recogito Studio CSV export (which contains more information than the GeoJSON export) into a Linked Places-compliant JSON-LD file with the relevant details to enhance and contextualise the visualisation. An interim step towards this might be to fully document the pipeline between these two tools, i.e. how the Recogito Studio output might be enhanced to optimise the input into Peripleo.</p>\n<p>An  issue  common  to  all  tools  and  resources  that  rely  on  external  services  for  part  of  their functionality is the extent to which those services are available. Our initial intention was to use the Geo-Tagger to link to place URIs from the World-Historical Gazetteer (WHG), to provide a greater level of historical accuracy than linking to their modern-day equivalents. However, following several extended periods of WHG server downtime that prevented geo-tagging from taking place, it was decided to instead use Wikidata URIs (prioritising server availability over temporal nuance), as Recogito Studio does not currently allow the same piece of text to be geo- tagged with multiple gazetteer references, and time was limited. This experience highlights a potential barrier to using external services for entity definition and classification, particularly when  they  are  not  supported  by  major,  well-resourced  infrastructures.  Such  an  issue  is  by\nno means unique to Recogito Studio and the data sources connected to its Geo-Tagger plugin; however, it is likely to be compounded with the introduction of further plugins that rely on external  services,  such  as  those  recommended  above.  While  we  would  still  argue  that  such future developments would bring highly desirable functionality, we must also be pragmatic in acknowledging their potential shortcomings.</p>\n<p>Where there are concerns surrounding potential user dissatisfaction, or (as in our case) where work must be completed within a short timeframe, a logical solution is to opt for reliability by linking to major, generic data sources like Wikidata, even if this entails compromising on historical accuracy. However, if time and resources allow, an additional measure could be to add  the  relevant  historical  places  to  Wikidata,  as  demonstrated  by  Zhu  et  al.  (2023).  In  the specific  case  of  Recogito  Studio’s  Geo-Tagger  plugin,  there  is  an  added  complication  that the system queries all entity types in Wikidata rather than focusing on places. As a result, accidental errors could creep in, where place names are incorrectly linked to people or objects with similar names, for example, particularly if the user uncritically accepts the first match presented by the system.</p>\n<p>Our findings have also prompted some reflections on the suitability of applying these methods to  museum  collections  data  more  generally.  Some  of  these  relate  closely  to  the  growing Collections  as  Data  movement  (Padilla  et  al.,  2023a;  2019)  to  promote  responsible  reuse  of data produced by cultural heritage institutions. The NMS dataset was well-suited to annotation in that it includes multiple fields containing unstructured text, alongside its more structured fields  containing  (for  example)  standardised  names,  places,  dates  and  terms  from  controlled vocabularies. Annotation in this case has provided added value, by superimposing an additional semantic  layer  that  enhances  the  existing  information  without  altering  the  underlying  data structure.  However,  this  is  largely  a  result  of  the  institution’s  procedures  for  managing information: text from research notes and exhibition labels is included as part of an object’s record in the collection management system, which might not be the case in other institutions. It  should  also  be  noted  that  this  type  of  unstructured  data  can  sometimes  hold  sensitive information that museums do not wish to make public; therefore, some fields are likely to be redacted to avoid the risk of making such information more discoverable.</p>\n<p>Another factor affecting the potential for enhancing museum data through semantic annotation is  that  of  institutional  policy  and  procedure  for  cataloguing  objects.  While  some  catalogue records,  particularly  for  those  objects  that  have  formed  part  of  major  exhibitions  or  are  on permanent display, contain rich historical information, others are described solely in relation to\ntheir physical appearance and functionality. The inclusion of information about how a collections dataset  has  been  structured  (with  the  aim  of  optimising  interoperability),  accompanied  by transparency about any omissions or biases, are key components of the Vancouver Statement (Padilla  et  al.,  2023b),  which  outlines  principles  for  cultural  heritage  institutions  to  follow when publishing their collections as openly available data.</p>\n<p>The  suitability  of  a  collections  dataset  for  annotation  is  usually  therefore  dependent  on  the purpose  of  that  annotation:  detailed  physical  descriptions  provide  an  excellent  basis  for representing  aspects  of  an  object  through  modelling  part-whole  relationships,  material composition, or construction techniques, for example. However, this type of information is less compatible with the aim of representing object itineraries across time and space. To achieve the aim of representing object itineraries for a collection at scale, further research on the objects and/or enhancement of the catalogue records themselves might therefore be required, which is often not possible within the scope of day-to-day museum processes and would necessitate specific project funding.</p>\n<h2>5. Implications/Applications</h2>\n<p>Our study, which incorporated the production of the dataset that accompanies this paper, has\ndemonstrated Recogito Studio’s usefulness and usability for annotating cultural heritage data. In\nparticular, we have shown how the platform might be used by cultural heritage professionals to\nannotate data about object itineraries, and how the resulting data might be processed further to\nfacilitate spatial visualisation. Increasing the machine-readability of this text will facilitate its\nuse in data storytelling, potentially capturing the imagination of new audiences and expanding\nthe  scope  for  collections  research.  However,  we  have  also  identified  key  areas  for  further\ndevelopment, which would enable this approach to be applied to a broader range of cultural\nheritage data, in a more scalable way, and by a wider user community.</p>\n<p>The first of the above aims points towards the extension of the object itineraries data model,\nwhich  is  currently  based  solely  on  a  sample  of  objects  that  belong  to  a  single  category\n(navigational  instruments)  and  that  are  held  by  a  single  institution.  Applying  this  approach\nto collections data that describes other types of objects and from other institutions will reveal\nadditional entities and relationships that form part of their itineraries. As noted above, it might\nbe  similarly  beneficial  to  annotate  related  data  that  exists  separately  from  the  institution’s\ncatalogue, such as previous exhibition texts. In doing so, the data model will gradually become\nmore broadly applicable to different types of cultural heritage data and for representing a wider\nrange of object itineraries involving different cultures, geographies and temporalities.</p>\n<p>Middle et al.  Journal of Open Humanities Data  DOI: 10.5334/johd.273\f11</p>\n<p>To increase scalability, we could automate entity recognition using NER technologies, combined\nwith  aligning  entities  to  established  vocabularies.  Such  an  approach  could  additionally\nbe  beneficial  for  working  with  more  ‘messy’  catalogue  data,  where  fields  have  been  used\ninconsistently  or  contain  extraneous  information.  An  advantage  of  a  combined  annotation/\nNER approach is that it does not require the data to already be ‘cleaned’/‘normalised’ before\nits  application.  While  implementing  this  extension  to  Recogito  Studio  would  be  significant,  a\nscoping study could investigate potential solutions and their integration into the platform’s user\ninterface. This would ensure usability for non-technical users.</p>\n<p>Alternatively,  Recogito  Studio  has  the  potential  to  be  used  on  a  larger  scale  as  a  citizen\nscience platform, which could facilitate the manual annotation of cultural heritage data on a\nlarger scale. Such initiatives do, however, require careful management and moderation. The\nimplementation of Recogito Studio in this way would also require the usability improvements\nrecommended in section 4 to ensure the platform’s accessibility to non-specialists. Additionally,\nthe task of processing and analysing the resulting data would still fall to the cultural heritage\nprofessionals themselves, potentially necessitating further technological interventions.</p>\n<p>To enhance scalability and interoperability, we could facilitate the production of Linked Open\nData. Linked Open Data would allow our annotations to be more easily integrated with other\ndatasets and tools, enabling new insights and applications. While integrating this functionality\ninto  Recogito  Studio  for  accurate  object  itinerary  representation  is  complex,  an  intermediary\nstep  would  be  developing  workflows  using  existing  software  to  convert  annotation  export\nCSVs  to  RDF.  This  process,  particularly  for  annotations  using  our  data  model  and  protocol,\nwould involve deciphering layered annotations based on their text positions. This could be a\nchallenging task, ideally hidden from the end user.</p>\n<p>Having discussed the potential for future scalability, it might also be worth noting here that\nin many cases, such scalability might not be required. After all, the approach described in this\npaper might instead be better suited to the representation of smaller object assemblages whose\ndata can be enhanced manually through further research, rather than attempting to apply it to\nthe visualisation and connection of entire collections.</p>\n<p>Finally, regarding our third aim of expansion of the user community, we need to evaluate and\ndevelop Recogito Studio without compromising usability, and provide an opportunity to extend\nits capabilities. Our recommended developments, as outlined above, will require one or more\nlarger-scale projects. Following Tasovac et al.’s (2020) call for cultural heritage professionals to\nbe “recognised as essential partners in research”, we acknowledge that if we are to successfully\noptimise this platform for effective application to cultural heritage data, then we should engage\nmore directly with the sector by including one or more cultural heritage professionals on any\nfuture project teams.</p>\n<h2>Acknowledgements</h2>\n<p>The authors would like to thank Rainer Simon and Jamie Folsom for their development work\non Recogito Studio and the technical support they provided throughout this study, as well as\nGethin Rees for his advice on transforming our geo-tag data to a Peripleo-compatible format.\nSpecial  thanks  are  also  owed  to  the  five  participants  who  took  part  in  our  user  evaluation\nand to National Museums Scotland for providing the data that formed the foundation for our\nannotation work.</p>\n<h2>Funding Information</h2>\n<p>This study was funded through the Open University’s Open Societal Challenges Programme.</p>\n<h2>Competing Interests</h2>\n<p>The authors have no competing interests to declare.</p>\n<h2>Author Contributions</h2>\n<ul>\n<li>Sarah  Middle  –  Conceptualization,  Data  curation,  Funding  acquisition,  Investigation, Methodology, Visualization, Writing – original draft, Writing – review &#x26; editing.</li>\n<li>Maria  Aristeidou  –  Conceptualization,  Formal  analysis,  Funding  acquisition,  Investigation, Methodology, Project administration, Supervision, Writing – original draft.</li>\n<li>Elton Barker – Conceptualization, Funding acquisition, Methodology, Project administration, Supervision, Writing – review &#x26; editing.</li>\n<li>Daniel Pett – Conceptualization, Funding acquisition, Project administration, Writing – review &#x26; editing.</li>\n<li>Sarah Alcock – Formal analysis, Investigation.</li>\n</ul>\n<h2>Author Affiliations</h2>\n<ul>\n<li>Sarah Middle Classical Studies, Open University, Milton Keynes, UK <a href=\"https://orcid.org/0000-0001-7800-6777\">orcid.org/0000-0001-7800-6777</a></li>\n<li>Maria Aristeidou Institute of Educational Technology, Open University, Milton Keynes, UK <a href=\"https://orcid.org/0000-0001-5877-7267\">orcid.org/0000-0001-5877-7267</a></li>\n<li>Elton Barker Classical Studies, Open University, Milton Keynes, UK <a href=\"https://orcid.org/0000-0001-9517-1176\">orcid.org/0000-0001-9517-1176</a></li>\n<li>Daniel Pett <a href=\"https://orcid.org/0000-0002-0246-2335\">orcid.org/0000-0002-0246-2335</a> St Edmund’s College, University of Cambridge, Cambridge, UK</li>\n<li>Sarah Alcock Institute of Educational Technology, Open University, Milton Keynes, UK <a href=\"https://orcid.org/0009-0003-2755-7669\">orcid.org/0009-0003-2755-7669</a></li>\n</ul>\n<h2>References</h2>\n<ul>\n<li>Axiell. (2024). Axiell Collections. Axiell. <a href=\"https://www.axiell.com/solutions/product/axiell-collections/\">https://www.axiell.com/solutions/product/axiell-collections/</a></li>\n<li>Candela, G. (2023). Towards a semantic approach in GLAM Labs: The case of the Data Foundry at the National Library of Scotland. Journal of Information Science. <a href=\"https://doi.org/10.1177/01655515231174386\">https://doi.org/10.1177/01655515231174386</a></li>\n<li>Collections Trust. (2016). Spectrum v.4.0 (archived). Collections Trust. Retrieved 4 November 2024. Retrieved from <a href=\"https://collectionstrust.org.uk/resource/the-spectrum-standard-v4-0/\">https://collectionstrust.org.uk/resource/the-spectrum-standard-v4-0/</a></li>\n<li>Collections Trust. (n.d.). Spectrum. Collections Trust. Retrieved 7 October 2024. Retrieved from <a href=\"https://collectionstrust.org.uk/spectrum/\">https://collectionstrust.org.uk/spectrum/</a></li>\n<li>Dunn, S., Earl, G., Foka, A., and Wootton, W. (2019). Spatial Narratives in Museums and Online: TheBirth of the Digital Object Itinerary. In T. Giannini &#x26; J. P. Bowen (Eds.), Museums and Digital Culture: New Perspectives and Research (pp. 253–271). Cham: Springer International Publishing. <a href=\"https://doi.org/10.1007/978-3-319-97457-6_12\">https://doi.org/10.1007/978-3-319-97457-6_12</a></li>\n<li>Finstad, K. (2010). The usability metric for user experience. Interacting with Computers, 22(5), 323–327. <a href=\"https://doi.org/10.1016/j.intcom.2010.04.004\">https://doi.org/10.1016/j.intcom.2010.04.004</a></li>\n<li>Gadd, S., &#x26; Simon, R. (2023). Peripleo: A platform for visualising and exploring linked places data. Journal of Open Humanities Data, 9(1), 1–8. <a href=\"https://doi.org/10.5334/johd.266\">https://doi.org/10.5334/johd.266</a></li>\n<li>Gadd, S., Simon, R., &#x26; Rees, G. (2024). Peripleo [Computer software]. The British Library. Retrieved 28 October 2024. Retrieved from <a href=\"https://github.com/britishlibrary/peripleo\">https://github.com/britishlibrary/peripleo</a> (Original work published 2022)</li>\n<li>Getty Research Institute. (2023). Art and Architecture Thesaurus. Getty Vocabularies: LOD. Retrieved 28 October 2024. Retrieved from <a href=\"https://vocab.getty.edu/aat/\">https://vocab.getty.edu/aat/</a></li>\n<li>Grossner, K., Zijdeman, R., Shaw, R. and Elwert, F. (2024). The Linked Places format (LPF). GitHub. Retrieved 28 October 2024. Retrieved from <a href=\"https://github.com/LinkedPasts/linked-places-format\">https://github.com/LinkedPasts/linked-places-format</a></li>\n<li>Jameson, L., &#x26; Simon, R. (2024). Recogito-Studio [PLpgSQL]. Recogito. Retrieved 30 October 2024. Retrieved from <a href=\"https://github.com/recogito/recogito-studio\">https://github.com/recogito/recogito-studio</a> (Original work published 2024)</li>\n<li>Kahn, R., Isaksen, L., Barker, E., Simon, R., de Soto Cañamares, P., &#x26; Vitale, V. (2016). Pelagios—Connecting Histories of Place. Part I: From Association to Community. International Journal of Humanities and Arts Computing, 10(1–2), 1–16. <a href=\"https://doi.org/10.3366/ijhac.2016.0140\">https://doi.org/10.3366/ijhac.2016.0140</a></li>\n<li>Linked Art Editorial Board. (n.d.-a). Linked Art. Retrieved 28 October 2024. Retrieved from <a href=\"https://linked.art/\">https://linked.art/</a> Linked Art Editorial Board. (n.d.-b). Types and Classifications. Linked Art. Retrieved 28 October 2024. Retrieved from <a href=\"https://linked.art/model/base/#types-and-classifications\">https://linked.art/model/base/#types-and-classifications</a></li>\n<li>Luthra, M., Todorov, K., Jeurgens, C., &#x26; Colavizza, G. (2023). Unsilencing colonial archives via automated entity recognition. Journal of Documentation, 80(5), 1080–1105. <a href=\"https://doi.org/10.1108/\">https://doi.org/10.1108/</a> JD-02-2022-0038</li>\n<li>Middle et al.  Journal of Open Humanities Data  DOI: 10.5334/johd.273-Musen, M. A. (2015). The Protégé project: A look back and a look forward. AI Matters, 1(4), 4–12.13 <a href=\"https://doi.org/10.1145/2757001.2757003\">https://doi.org/10.1145/2757001.2757003</a></li>\n<li>Nielsen, J. and Landauer, T. K. (1993). A mathematical model of the finding of usability problems. In CHI ’93: Proceedings of the INTERACT ’93 and CHI ’93 Conference on Human Factors in Computing Systems (pp. 206–213). ACM. <a href=\"https://doi.org/10.1145/169059.169166\">https://doi.org/10.1145/169059.169166</a></li>\n<li>Padilla, T., Allen, L., Frost, H., Potvin, S., Russey Roke, E., &#x26; Varner, S. (2019). Final Report – Always Already Computational: Collections as Data. Collections as Data. <a href=\"https://doi.org/10.5281/zenodo.7883759\">https://doi.org/10.5281/zenodo.7883759</a></li>\n<li>Padilla, T., Scates Kettler, H., &#x26; Shorish, Y. (2023a). Collections as Data: Part to Whole Final Report. Collections as Data. <a href=\"https://doi.org/10.5281/zenodo.10161976\">https://doi.org/10.5281/zenodo.10161976</a></li>\n<li>Padilla, T., Scates Kettler, H., Varner, S., &#x26; Shorish, Y. (2023b). Vancouver Statement on Collections as Data. Collections as Data. <a href=\"https://doi.org/10.5281/zenodo.8341519\">https://doi.org/10.5281/zenodo.8341519</a></li>\n<li>Performant Software. (n.d.). Recogito Studio. Retrieved 30 October 2024. Retrieved from <a href=\"https://recogitostudio.org/\">https://recogitostudio.org/</a></li>\n<li>Rees, G., Gadd, S., Horgan, J., Hunt, A., Isaksen, L., Morris, V., Musson, A., Simon, R., Strachan, P., &#x26; Vitale, V. (2022). Locating a National Collection (LaNC). Towards a National Collection. <a href=\"https://doi.org/10.5281/zenodo.7071654\">https://doi.org/10.5281/zenodo.7071654</a></li>\n<li>Simon, R. (2024). Recogito GeoTagger Plugin [TypeScript]. Recogito. Retrieved 30 October 2024. Retrieved from <a href=\"https://github.com/recogito/geotagger\">https://github.com/recogito/geotagger</a> (Original work published 2024)</li>\n<li>Simon, R., Barker, E., Isaksen, L., &#x26; de Soto Cañamares, P. (2015). Linking Early Geospatial Documents, One Place at a Time: Annotation of Geographic Documents with Recogito. E-Perimetron, 10(2), 49–59. Retrieved 30 October 2024. Retrieved from <a href=\"https://www.e-perimetron.org/Vol_10_2/Simon_et_al.pdf\">https://www.e-perimetron.org/Vol_10_2/Simon_et_al.pdf</a></li>\n<li>Simon, R., Barker, E., Isaksen, L., &#x26; de Soto Cañamares, P. (2017). Linked Data Annotation Without the Pointy Brackets: Introducing Recogito 2. Journal of Map &#x26; Geography Libraries, 13(1), 111–132. <a href=\"https://doi.org/10.1080/15420353.2017.1307303\">https://doi.org/10.1080/15420353.2017.1307303</a></li>\n<li>Simon, R., Isaksen, L., Barker, E., &#x26; de Soto Cañamares, P. (2016). Peripleo: A Tool for Exploring Heterogeneous Data through the Dimensions of Space and Time. The Code4Lib Journal, 31. Retrieved  30 October 2024. Retrieved from <a href=\"http://journal.code4lib.org/articles/11144\">http://journal.code4lib.org/articles/11144</a></li>\n<li>Simon, R., Vitale, V., Kahn, R., Barker, E., &#x26; Isaksen, L. (2019). Revisiting Linking Early Geospatial Documents with Recogito. E-Perimetron, 14(3), 150–163. Retrieved 30 October 2024. Retrieved from <a href=\"https://www.e-perimetron.org/Vol_14_3/Simon_et_al.pdf\">https://www.e-perimetron.org/Vol_14_3/Simon_et_al.pdf</a></li>\n<li>Tasovac, T., Chambers, S., &#x26; Tóth-Czifra, E. (2020). Cultural Heritage Data from a Humanities Research Perspective: A DARIAH Position Paper. Retrieved 11 December 2024. Retrieved from <a href=\"https://hal.science/hal-02961317\">https://hal.science/hal-02961317</a></li>\n<li>Universität Bonn. (2024). Introduction of Recogito Studio. Hochschulrechenzentrum. Retrieved 30 October 2024. Retrieved from <a href=\"https://www.hrz.uni-bonn.de/en/news/introduction-recogito-studio\">https://www.hrz.uni-bonn.de/en/news/introduction-recogito-studio</a> 2024. Retrieved from <a href=\"https://www.hrz.uni-bonn.de/en/news/introduction-recogito-studio\">https://www.hrz.uni-bonn.de/en/news/introduction-recogito-studio</a></li>\n<li>Vitale, V., de Soto, P., Simon, R., Barker, E., Isaksen, L., &#x26; Kahn, R. (2021). Pelagios—Connecting</li>\n<li>Histories of Place. Part I: Methods and Tools. International Journal of Humanities and Arts Computing,15(1–2), 5–32. <a href=\"https://doi.org/10.3366/ijhac.2021.0260\">https://doi.org/10.3366/ijhac.2021.0260</a></li>\n<li>W3C OWL Working Group. (2012). OWL 2 Web Ontology Language Document Overview (Second Edition).</li>\n<li>W3C. Retrieved 28 October 2024. Retrieved from <a href=\"https://www.w3.org/TR/owl2-overview/\">https://www.w3.org/TR/owl2-overview/</a></li>\n<li>Wikimedia. (2023). Wikidata. Retrieved 28 October 2024. Retrieved from <a href=\"https://www.wikidata.org/wiki/Wikidata:Main_Page\">https://www.wikidata.org/wiki/Wikidata:Main_Page</a></li>\n<li>Zhao, F. (2023). A systematic review of Wikidata in Digital Humanities projects. Digital Scholarship in the Humanities, 38(2), 852–874. <a href=\"https://doi.org/10.1093/llc/fqac083\">https://doi.org/10.1093/llc/fqac083</a></li>\n<li>Zhu, L., Xu, A., Deng, S., Heng, G., &#x26; Li, X. (2023). Entity Management Using Wikidata for Cultural Heritage Information. Cataloging &#x26; Classification Quarterly, 61(1), 20–46. <a href=\"https://doi.org/10.1080/01639374.2023.2188338\">https://doi.org/10.1080/01639374.2023.2188338</a></li>\n</ul>","timeToRead":26,"frontmatter":{"slug":"/papers/discovering-object-stories","title":"Discovering Object Stories: Linking Unstructured Museum Data Through Semantic Annotation","description":null,"date":"January 24, 2025","tags":["digital transformation","museums","archaeology","digital humanities","digital heritage","digital archaeology","linked data"],"authors":["Sarah Middle","Maria Aristeidou","Elton Barker","Daniel Pett","Sarah Alcock"],"citation":"Middle, S., Aristeidou, M.,S. (2025). Discovering Object Stories: Linking Unstructured Museum Data Through Semantic Annotation. Journal of Open Humanities Data, 11:5, pp. 1–13. DOI: https://doi.org/10.5334/johd.273","featuredImg":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#a8d8d8","images":{"fallback":{"src":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/6a8a8/background.png","srcSet":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/57cb0/background.png 150w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/d7d51/background.png 300w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/6a8a8/background.png 600w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/8c7d2/background.png 1200w","sizes":"(min-width: 600px) 600px, 100vw"},"sources":[{"srcSet":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/628fd/background.webp 150w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/8aaca/background.webp 300w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/ec39e/background.webp 600w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/49a25/background.webp 1200w","type":"image/webp","sizes":"(min-width: 600px) 600px, 100vw"}]},"width":600,"height":600}}},"background":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#a8d8d8","images":{"fallback":{"src":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/6a8a8/background.png","srcSet":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/57cb0/background.png 150w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/d7d51/background.png 300w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/6a8a8/background.png 600w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/8c7d2/background.png 1200w","sizes":"(min-width: 600px) 600px, 100vw"},"sources":[{"srcSet":"/static/02ee8d1baa7604ef53ec0d27df47b0c9/628fd/background.webp 150w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/8aaca/background.webp 300w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/ec39e/background.webp 600w,\n/static/02ee8d1baa7604ef53ec0d27df47b0c9/49a25/background.webp 1200w","type":"image/webp","sizes":"(min-width: 600px) 600px, 100vw"}]},"width":600,"height":600}}},"geo_lat":null,"geo_lon":null}}},"pageContext":{"slug":"/papers/discovering-object-stories","id":"67b0a9d8-d435-5f38-878c-6c12d71229a7"}},"staticQueryHashes":["2240598579","2679611508","3600676621"],"slicesMap":{}}